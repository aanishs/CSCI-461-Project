#!/usr/bin/env python3
"""
Run All Key Analyses from Final Report

This script executes all major analyses referenced in the final report:
1. Threshold Calibration (Section 4.4)
2. 5-Fold Cross-Validation (Section 5.4)
3. Feature Selection (Section 6.2)
4. Fairness Analysis (Section 6.6)
5. Temporal Validation (Section 4.6)

Results are saved to report_figures/ directory.

Usage:
    python run_all_analyses.py

Expected runtime: ~10-15 minutes on standard laptop
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / 'src'))

print("="*80)
print("RUNNING ALL KEY ANALYSES FROM FINAL REPORT")
print("="*80)
print("\nThis will execute all major analyses and save results to report_figures/")
print("Expected runtime: 10-15 minutes\n")

# Create output directory if needed
Path("report_figures").mkdir(exist_ok=True)

# Analysis 1: Threshold Calibration (Section 4.4)
print("\n" + "="*80)
print("1. THRESHOLD CALIBRATION (Section 4.4)")
print("="*80)
try:
    from threshold_calibration import run_proper_threshold_calibration

    print("\nRunning proper threshold calibration with train/cal/test split...")
    threshold, cal_metrics, test_metrics, default_metrics, model = run_proper_threshold_calibration()

    print("\n‚úÖ Threshold calibration complete!")
    print(f"   Calibrated threshold: {threshold:.4f}")
    print(f"   Test F1 (calibrated): {test_metrics['f1']:.4f}")
    print(f"   Test F1 (default 0.5): {default_metrics['f1']:.4f}")
    print(f"   Improvement: {((test_metrics['f1']/default_metrics['f1']-1)*100):.1f}%")

except Exception as e:
    print(f"\n‚ùå Error in threshold calibration: {e}")

# Analysis 2: 5-Fold Cross-Validation (Section 5.4)
print("\n" + "="*80)
print("2. 5-FOLD CROSS-VALIDATION (Section 5.4)")
print("="*80)
try:
    from kfold_evaluation import run_kfold_evaluation

    print("\nRunning 5-fold user-grouped cross-validation...")
    reg_results, clf_results = run_kfold_evaluation(n_splits=5)

    print("\n‚úÖ 5-fold CV complete!")
    print(f"   Regression MAE: {reg_results['overall']['mean_mae']:.2f} ¬± {reg_results['overall']['std_mae']:.2f}")
    print(f"   Classification F1: {clf_results['overall']['mean_f1']:.2f} ¬± {clf_results['overall']['std_f1']:.2f}")
    print(f"   Classification ROC-AUC: {clf_results['overall']['mean_roc_auc']:.2f} ¬± {clf_results['overall']['std_roc_auc']:.2f}")

except Exception as e:
    print(f"\n‚ùå Error in 5-fold CV: {e}")

# Analysis 3: Feature Selection (Section 6.2)
print("\n" + "="*80)
print("3. FEATURE SELECTION (Section 6.2)")
print("="*80)
try:
    from feature_selection import run_feature_selection_analysis

    print("\nRunning formal feature selection (RFE, L1, MI, Tree)...")
    reg_results, clf_results = run_feature_selection_analysis(n_features_to_select=20)

    print("\n‚úÖ Feature selection complete!")
    print(f"   Best regression method: Mutual Information (MAE={reg_results['mutual_info']['metrics']['mae']:.2f})")
    print(f"   Best classification method: RFE (F1={clf_results['rfe']['metrics']['f1']:.2f})")
    print(f"   Recommended: 20 features (vs 35 total)")

except Exception as e:
    print(f"\n‚ùå Error in feature selection: {e}")

# Analysis 4: Fairness Analysis (Section 6.6)
print("\n" + "="*80)
print("4. FAIRNESS ANALYSIS (Section 6.6)")
print("="*80)
try:
    from fairness_analysis import run_fairness_analysis

    print("\nRunning fairness analysis across user subgroups...")
    reg_fairness, clf_fairness = run_fairness_analysis()

    print("\n‚úÖ Fairness analysis complete!")
    print("   Performance varies across engagement, severity, and diversity subgroups")
    print("   See fairness_regression_results.csv and fairness_classification_results.csv")

except Exception as e:
    print(f"\n‚ùå Error in fairness analysis: {e}")

# Analysis 5: Temporal Validation (Section 4.6)
print("\n" + "="*80)
print("5. TEMPORAL VALIDATION (Section 4.6)")
print("="*80)
try:
    from temporal_validation import main as run_temporal_validation

    print("\nRunning temporal validation (August 2025 cutoff)...")
    # Redirect to avoid verbose output
    import io
    import contextlib

    f = io.StringIO()
    with contextlib.redirect_stdout(f):
        run_temporal_validation()

    output = f.getvalue()

    # Extract key results
    if "Temporal: 1." in output and "User-Grouped: 1." in output:
        print("\n‚úÖ Temporal validation complete!")
        print("   Train: May-July 2025, Test: Aug-Oct 2025")
        print("   See fig29_temporal_validation.png for results")
    else:
        print("\n‚úÖ Temporal validation complete! See report_figures/")

except Exception as e:
    print(f"\n‚ùå Error in temporal validation: {e}")

# Summary
print("\n" + "="*80)
print("ALL ANALYSES COMPLETE")
print("="*80)
print("\nüìÅ Results saved to report_figures/")
print("\nüìä Key output files:")
print("   - proper_threshold_calibration_results.csv")
print("   - kfold_regression_results.csv")
print("   - kfold_classification_results.csv")
print("   - fairness_regression_results.csv")
print("   - fairness_classification_results.csv")
print("   - feature_selection_regression_summary.csv")
print("   - feature_selection_classification_summary.csv")
print("   - fairness_analysis.png")
print("   - fig29_temporal_validation.png")
print("\n‚úÖ All key analyses from the final report have been executed successfully!")
print("\n" + "="*80)
