# Hyperparameter Search Configuration
# This file defines the search spaces for different models and data parameters

# Data-level hyperparameters
data_params:
  # High intensity threshold for classification
  high_intensity_threshold: [6, 7, 8]

  # Prediction windows (k days)
  prediction_window_k_days: [1, 3, 7, 14]

  # Feature windows (m days for time-window features)
  feature_window_m_days:
    - [3, 7]
    - [3, 7, 14]
    - [7, 14, 30]

  # Number of lag features
  n_lags: [2, 3, 5]

  # Feature set configurations
  feature_sets:
    - name: sequence_only
      include_sequence: true
      include_time_window: false
      include_engineered: false

    - name: time_window_only
      include_sequence: false
      include_time_window: true
      include_engineered: false

    - name: both
      include_sequence: true
      include_time_window: true
      include_engineered: false

    - name: all
      include_sequence: true
      include_time_window: true
      include_engineered: true

# Model hyperparameters for RandomizedSearch (exploration)
model_params_random:
  ridge:
    alpha: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]

  lasso:
    alpha: [0.001, 0.01, 0.1, 1.0, 10.0]

  decision_tree:
    max_depth: [3, 5, 10, 15, 20, null]
    min_samples_split: [2, 5, 10, 20]
    min_samples_leaf: [1, 2, 4, 8]

  random_forest:
    n_estimators: [50, 100, 200, 300]
    max_depth: [5, 10, 15, 20, null]
    min_samples_split: [2, 5, 10]
    min_samples_leaf: [1, 2, 4]
    max_features: ['sqrt', 'log2', 0.5, 1.0]

  xgboost:
    n_estimators: [50, 100, 200, 300]
    max_depth: [3, 5, 7, 10]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    subsample: [0.6, 0.8, 1.0]
    colsample_bytree: [0.6, 0.8, 1.0]
    min_child_weight: [1, 3, 5]

  lightgbm:
    n_estimators: [50, 100, 200, 300]
    max_depth: [3, 5, 7, 10, -1]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    subsample: [0.6, 0.8, 1.0]
    colsample_bytree: [0.6, 0.8, 1.0]
    num_leaves: [15, 31, 63, 127]
    min_child_samples: [5, 10, 20]

  logistic:
    C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
    penalty: ['l1', 'l2']
    solver: ['liblinear', 'saga']

# Model hyperparameters for GridSearch (fine-tuning)
model_params_grid:
  ridge:
    alpha: [0.1, 1.0, 10.0]

  lasso:
    alpha: [0.01, 0.1, 1.0]

  decision_tree:
    max_depth: [5, 10, 15]
    min_samples_split: [2, 10]
    min_samples_leaf: [1, 4]

  random_forest:
    n_estimators: [100, 200]
    max_depth: [10, 15, 20]
    min_samples_split: [2, 5]
    max_features: ['sqrt', 1.0]

  xgboost:
    n_estimators: [100, 200]
    max_depth: [5, 7]
    learning_rate: [0.05, 0.1]
    subsample: [0.8, 1.0]
    colsample_bytree: [0.8, 1.0]

  lightgbm:
    n_estimators: [100, 200]
    max_depth: [5, 7]
    learning_rate: [0.05, 0.1]
    num_leaves: [31, 63]

  logistic:
    C: [0.1, 1.0, 10.0]
    penalty: ['l2']

# Prediction targets
targets:
  # Target 1: Next single tic intensity
  next_intensity:
    - target_col: target_next_intensity
      task_type: regression
      description: "Predict intensity of next tic (1-10)"

    - target_col: target_next_high_intensity
      task_type: classification
      description: "Predict if next tic is high intensity (binary)"

  # Target 2: Future count of high-intensity episodes
  future_count:
    # Will be generated dynamically for each k_days value
    # Format: target_high_count_next_Kd
    description: "Predict count of high-intensity episodes in next k days"

  # Target 3: Time to next high-intensity episode
  time_to_event:
    - target_col: target_time_to_high_days
      task_type: regression
      description: "Predict days until next high-intensity episode"

# Search strategy
search_strategy:
  # Random search parameters
  random_search:
    n_iter: 100
    cv_splits: 3
    n_jobs: -1

  # Grid search parameters
  grid_search:
    cv_splits: 5
    n_jobs: -1

  # Which search to use for each phase
  exploration_phase:
    method: random_search
    models: [random_forest, xgboost, lightgbm]

  fine_tuning_phase:
    method: grid_search
    # Use top models from exploration
    top_n_models: 3

# Evaluation metrics
metrics:
  regression:
    primary: mae
    secondary: [rmse, r2, mape]

  classification:
    primary: f1
    secondary: [precision, recall, pr_auc, accuracy]
